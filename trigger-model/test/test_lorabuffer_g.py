import torch
import os
import json
import re
import math
from typing import List, Dict, Any
from lora_buffer import LoraOptimizer
from transformers import LlamaForCausalLM, LlamaTokenizer
from utils import load_config, get_device_info
from datasets import load_dataset
from peft import PeftModel
from sklearn.metrics import mean_absolute_error, mean_squared_error
from tqdm import tqdm

cfg = load_config("./config.yaml")

def extract_numeric_answer(output_text: str, label: str, max_val=1e6):
    match = re.search(r"final answer\s*is\s*:?\s*(-?\d+\.?\d*)", output_text.lower())
    if not match:
        lines = output_text.strip().split("\n")
        for line in reversed(lines[-5:]):
            match = re.search(r"(-?\d+\.?\d*)", line)
            if match:
                break
    if match:
        try:
            val = float(match.group(1))
            if math.isfinite(val) and abs(val) < max_val:
                return int(val), int(label)
        except:
            return None
    return None

def test_lora_buffer_data_as_cluster():
    model_path = "/path/to/your/trigger/models/llamma2/Llamma-2-7b-ukr-AEG"
    tokenizer = LlamaTokenizer.from_pretrained(model_path)
    base_model = LlamaForCausalLM.from_pretrained(model_path)

    device = torch.device(get_device_info()["device"])
    base_model.to(device).eval()

    data = load_dataset("json", data_files="/path/to/your/trigger/trigger-model/gsm8k_level1.jsonl")["train"]
    cluster = {
        "cluster_id": -1,
        "label": "pubmedqa_cluster",
        "samples": [dict(sample) for sample in data]
    }

    print(f"[INFO] æž„é€ äº† 1 ä¸ªè™šæ‹Ÿ Clusterï¼Œæ ·æœ¬æ•°: {len(cluster['samples'])}")
    best_config = LoraOptimizer.optimize_lora_for_cluster(cluster, base_model, tokenizer, top_k=3)
    print(f"[INFO] æœ€ä¼˜ LoRA é…ç½®: {best_config}")

    for i, entry in enumerate(LoraOptimizer.lora_buffer[:3]):
        checkpoint_path = entry.get("checkpoint_path")
        if not checkpoint_path or not os.path.exists(checkpoint_path):
            print(f"âš ï¸ æ— æ•ˆè·¯å¾„ï¼Œè·³è¿‡ï¼š{checkpoint_path}")
            continue

        print(f"\n=== è¯„ä¼°ç¬¬ {i+1} ä¸ª LoRA Adapter: {checkpoint_path} ===")

        lora_model = PeftModel.from_pretrained(base_model, checkpoint_path)
        lora_model.to(device).eval()

        y_true, y_pred = [], []
        for sample in tqdm(data, desc=f"[Adapter {i+1}]"):
            prompt = f"{sample['prompt']}\n{sample['completion']}"
            label = sample.get("label", None)
            if label is None:
                continue
            inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512, padding=True).to(device)

            with torch.no_grad():
                outputs = lora_model.generate(
                    input_ids=inputs["input_ids"],
                    attention_mask=inputs["attention_mask"],
                    max_new_tokens=1024,
                    do_sample=False,
                    num_beams=3,
                    early_stopping=True,
                    repetition_penalty=1.2,
                    eos_token_id=tokenizer.eos_token_id
                )

            output_text = tokenizer.decode(outputs[0][inputs["input_ids"].shape[1]:], skip_special_tokens=True)
            result = extract_numeric_answer(output_text, label)
            if result:
                pred, true_label = result
                y_pred.append(pred)
                y_true.append(true_label)
            else:
                print("[è·³è¿‡] æ— æ³•æå–æœ‰æ•ˆæ•°å­—")

        print(f"\n[Adapter {i+1}] è¯„ä¼°ç»“æžœï¼š")
        if len(y_true) == 0:
            print("âŒ æ— æœ‰æ•ˆé¢„æµ‹ç»“æžœï¼Œå¯èƒ½è¾“å‡ºæ ¼å¼æœ‰è¯¯")
        else:
            exact_match = sum(yt == yp for yt, yp in zip(y_true, y_pred)) / len(y_true)
            mae = mean_absolute_error(y_true, y_pred)
            mse = mean_squared_error(y_true, y_pred)
            print(f"âœ… ç²¾ç¡®åŒ¹é…çŽ‡ (Exact Match): {exact_match:.4f}")
            print(f"ðŸ“‰ å¹³å‡ç»å¯¹è¯¯å·® (MAE): {mae:.4f}")
            print(f"ðŸ“‰ å‡æ–¹è¯¯å·® (MSE): {mse:.4f}")
            print(f"âœ… æœ‰æ•ˆé¢„æµ‹æ•°é‡: {len(y_true)} / {len(data)}")
            print(f"âœ… æ•°å­—æå–æˆåŠŸçŽ‡: {len(y_true)/len(data):.4f}")
            result_log_path = f"/path/to/your/trigger/output/adapter_eval_gsm8k500_{i+1}.log"  
            with open(result_log_path, "w", encoding="utf-8") as f:
                f.write(f"=== Adapter {i+1} è¯„ä¼°ç»“æžœ ===\n")
                f.write(f"Checkpoint: {checkpoint_path}\n")
                f.write(f"âœ… ç²¾ç¡®åŒ¹é…çŽ‡ (Exact Match): {exact_match:.4f}\n")
                f.write(f"ðŸ“‰ å¹³å‡ç»å¯¹è¯¯å·® (MAE): {mae:.4f}\n")
                f.write(f"ðŸ“‰ å‡æ–¹è¯¯å·® (MSE): {mse:.4f}\n")
                f.write(f"âœ… æœ‰æ•ˆé¢„æµ‹æ•°é‡: {len(y_true)} / {len(data)}\n")
                f.write(f"âœ… æ•°å­—æå–æˆåŠŸçŽ‡: {len(y_true)/len(data):.4f}\n")      

test_lora_buffer_data_as_cluster()